{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69e05479",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84d98441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import faiss\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b98c172",
   "metadata": {},
   "source": [
    "### Load necessary data and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "17d8628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_location = \"../eda/code/cyoung_eda.db\"  # soccer dataset\n",
    "db_location = \"../data/car_1.sqlite\"\n",
    "schema_location = \"../data/car_metadata.xlsx\"\n",
    "\n",
    "def get_column_metadata():\n",
    "    return pd.read_excel(schema_location, sheet_name=\"schema_metadata\")[\"full_column_metadata\"].tolist()\n",
    "\n",
    "def get_embedding_model():\n",
    "    return SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def get_model_and_tokenizer(use_saved_model=True):\n",
    "    model_name = \"cssupport/t5-small-awesome-text-to-sql\"\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = None\n",
    "    if use_saved_model:\n",
    "        saved_model_path = \"../model_checkpoints/fine-tuned-model\"\n",
    "        model = T5ForConditionalGeneration.from_pretrained(saved_model_path).to(device)\n",
    "    else:\n",
    "        model = T5ForConditionalGeneration.from_pretrained(model_name).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cf22bb",
   "metadata": {},
   "source": [
    "### Vector embedding and similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "915a60a0",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99205262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_k(nl_query):\n",
    "    min_k_value = 1\n",
    "    doc = spacy.load(\"en_core_web_sm\")(nl_query)\n",
    "    keywords = []\n",
    "    for token in doc:\n",
    "        if token.pos_ in [\"NOUN\", \"ADJ\"] and token.text.lower() not in STOP_WORDS:\n",
    "            keywords.append(token)\n",
    "    optimal_k = max(min_k_value, len(keywords))\n",
    "    print(f\"Keywords in natural-language query: {keywords}\")\n",
    "    print(f\"Optimal k is {optimal_k}\")\n",
    "    return max(min_k_value, optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "abcdd107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_vector_embedding(text, embedding_model):\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    return embedding_model.encode(text)\n",
    "\n",
    "def search_similar_columns(\n",
    "    nl_query_embedding,\n",
    "    column_embeddings,\n",
    "    raw_column_text,\n",
    "    num_of_search_results=None\n",
    "):\n",
    "    # build the index\n",
    "    vector_size = column_embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(vector_size)\n",
    "    index.add(np.array(column_embeddings))\n",
    "\n",
    "    # perform search\n",
    "    D, I = index.search(np.array(nl_query_embedding), k=num_of_search_results)\n",
    "\n",
    "    # convert results from embeddings back to natural language\n",
    "    return [raw_column_text[i] for i in I[0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8db462",
   "metadata": {},
   "source": [
    "### Convert search results to create table statements with only those columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47b343a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns create statement for given table\n",
    "def get_table_create_statement(table_name):\n",
    "    conn = sqlite3.connect(db_location)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"SELECT sql FROM sqlite_master WHERE type='table' AND name='{table_name}'\")\n",
    "    statement = cursor.fetchone()[0]\n",
    "    conn.close()\n",
    "    return statement\n",
    "\n",
    "# returns create table statements with only the columns that are relevant\n",
    "def filter_table_create_statement(relevant_columns_info):\n",
    "    table_columns_map = {}\n",
    "    for relevant_column_info in relevant_columns_info:\n",
    "        table = relevant_column_info.split(\",\")[0].split(\":\")[1].strip()\n",
    "        column = relevant_column_info.split(\",\")[1].split(\":\")[1].strip()\n",
    "        if table not in table_columns_map:\n",
    "            table_columns_map[table] = []\n",
    "        table_columns_map[table].append(column)\n",
    "    print(table_columns_map)\n",
    "    filtered_table_create_statements = []\n",
    "\n",
    "    for table_name, relevant_columns in table_columns_map.items():\n",
    "        raw_sql = get_table_create_statement(table_name)\n",
    "\n",
    "        filtered_lines = []\n",
    "        for line in raw_sql.split(\"\\n\"):\n",
    "            line_segments = [s.strip().replace(\"\\\"\", \"\").replace(\",\", \"\") for s in line.split(\"\\\" \")]\n",
    "            column_name = line_segments[0] if len(line_segments) > 0 else None\n",
    "            column_details = line_segments[1] if len(line_segments) > 1 else None\n",
    "            is_line_without_columns = line_segments[0].upper().startswith(\"CREATE\") or line_segments[0] == \")\"\n",
    "            \n",
    "            if is_line_without_columns:\n",
    "                continue\n",
    "\n",
    "            if \"FOREIGN\" in line:\n",
    "                if any(col in line for col in relevant_columns):\n",
    "                    filtered_lines.append(line.strip())\n",
    "\n",
    "            if column_name.strip() in relevant_columns:\n",
    "                filtered_lines.append(f\"{column_name} {column_details}\")\n",
    "\n",
    "        table_def = f\"CREATE TABLE {table_name} (\\n  \" + \",\\n  \".join(filtered_lines) + \"\\n)\"\n",
    "        filtered_table_create_statements.append(table_def)\n",
    "\n",
    "    return \"\\n\\n\".join(filtered_table_create_statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8365b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(nl_query, schema_context):\n",
    "    return f\"tables:\\n{schema_context}\\nquery for: {nl_query}\"\n",
    "\n",
    "def convert_nlq_to_sql(prompt, tokenizer, model):\n",
    "    device = next(model.parameters()).device\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_length=512)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "93397104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(query):\n",
    "    conn = sqlite3.connect(db_location)\n",
    "    cur = conn.cursor()\n",
    "    try:\n",
    "        cur.execute(query)\n",
    "        results = cur.fetchall()\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        return f\"SQL Error: {e}\"\n",
    "    finally:\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52f62d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sql(nl_query: str, num_of_search_results=None):\n",
    "    if num_of_search_results is None:\n",
    "        num_of_search_results = find_optimal_k(nl_query)\n",
    "    # load data and models\n",
    "    column_texts = get_column_metadata()\n",
    "    embedder = get_embedding_model()\n",
    "    tokenizer, model = get_model_and_tokenizer()\n",
    "\n",
    "    # convert to vector embeddings\n",
    "    column_vectors = convert_text_to_vector_embedding(column_texts, embedder)\n",
    "    query_vector = convert_text_to_vector_embedding(nl_query, embedder)\n",
    "\n",
    "    # find relevant colums\n",
    "    similar_columns = search_similar_columns(query_vector, column_vectors, column_texts, num_of_search_results)\n",
    "    # create input prompt\n",
    "    schema_text = filter_table_create_statement(similar_columns)\n",
    "    prompt = build_prompt(nl_query, schema_text)\n",
    "    print(f\"\\nInput prompt:\\n{prompt}\")\n",
    "\n",
    "    # convert to sql\n",
    "    sql = convert_nlq_to_sql(prompt, tokenizer, model)\n",
    "    return sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36598e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(natural_language_query, generated_sql, retrevied_value):\n",
    "    padding = 30\n",
    "    print(\"\\n\")\n",
    "    print(f\"{'Natural language query:':<{padding}}{natural_language_query}\")\n",
    "    print(f\"{'Generated SQL query:':<{padding}}{generated_sql}\")\n",
    "    print(f\"{'Query results:':<{padding}}{retrevied_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b17e9f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords in natural-language query: [cars, country]\n",
      "Optimal k is 2\n",
      "{'car_makers': ['Country'], 'cars_data': ['Year']}\n",
      "\n",
      "Input prompt:\n",
      "tables:\n",
      "CREATE TABLE car_makers (\n",
      "  Country TEXT,\n",
      "  FOREIGN KEY (Country) REFERENCES countries(CountryId)\n",
      ")\n",
      "\n",
      "CREATE TABLE cars_data (\n",
      "  Year INTEGER\n",
      ")\n",
      "query for: How many cars does each country have?\n",
      "\n",
      "\n",
      "Natural language query:       How many cars does each country have?\n",
      "Generated SQL query:          SELECT Country, COUNT(*) FROM car_makers JOIN countries ON car_makers.Country = countries.CountryId JOIN cars_data ON countries.Country = cars_data.Country GROUP BY Country\n",
      "Query results:                SQL Error: no such column: countries.Country\n"
     ]
    }
   ],
   "source": [
    "natural_language_query = \"How many cars does each country have?\"\n",
    "generated_sql = text_to_sql(natural_language_query)\n",
    "query_results = execute_sql(generated_sql)\n",
    "print_results(natural_language_query, generated_sql, query_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d4cb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
